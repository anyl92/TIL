## Byte Ordering

데이터가 저장되는 순서. 빅엔디안과 리틀엔디안이 있다.

- Big Endian
  - MSB가 가장 낮은 주소에 위치하는 저장 방식
  - 네트워크에서 데이터를 전송할 때 주로 사용됨
  - 양수/음수를 바로 파악할 수 있다
- Little Endian
  - MSB가 가장 높은 주소에 위치하는 저장 방식
  - 마이크로프로세서에서 주로 사용됨
  - 데이터가 먼저 오기 때문에 바로 연산을 할 수 있다



## 메모리, 프로세스, 쓰레드

### 메모리

- 컴퓨터에서 작업을 수행하기 위해 처리 대상이나 결과 등을 저장하기 위한 공간. 프로그램을 실행하기 위한 정보들은 메모리에 저장되어 처리된다.

메모리 공간은 크게 **스택, 힙, 데이터** 영역으로 나뉜다.

**데이터 영역**

- 전역 변수와 static 변수가 할당되는 영역
- 프로그램 시작과 동시에 할당, 종료되면 메모리에서 소멸

**스택 영역**

- 함수 호출 시 생성되는 지역 변수와 매개 변수가 저장되는 영역
- 함수 호출이 완료되면 사라짐

**힙 영역**

- 필요에 의해 동적으로 메모리를 할당할 때 사용
- 할당해야 할 메모리의 크기를 프로그램이 실행되는 동안 결정해야 하는 경우 유용하게 사용됨



### 프로세스

- 메모리에서 실행되고 있는 프로그램의 인스턴스
- 운영체제로부터 독립된 메모리 영역을 할당받는다. (다른 프로세스에 접근X)
- 프로세스들은 독립적이기 때문에 통신하기 위해 IPC를 사용한다.
- 최소 1개의 쓰레드(메인 쓰레드)를 가지고 있다.



### 쓰레드

- 프로세스 내에서 할당받은 자원을 이용해 동작하는 실행 단위
- 쓰레드는 프로세스 내에서 stack만 따로 할당 받고, code, data, heap 영역은 공유한다.
  stack에는 함수 호출 정보가 저장되는데, 이를 공유하면 실행 순서가 복잡해진다.
- 프로세스의 자원을 공유하기 때문에 다른 쓰레드에 의한 결과를 즉시 확인 가능하다.
- 프로세스 내에 존재하며 프로세스가 할당받은 자원을 이용하여 실행된다.



#### 멀티 프로세스 VS 멀티 쓰레드

멀티 프로세스 - 하나의 프로그램을 여러 개의 프로세스로 구성하여 각 프로세스가 1개의 작업을 처리하도록 하는 것

- 1개의 프로세스가 죽어도 자식 프로세스 이외의 다른 프로세스들은 계속 실행된다.
- Context Switching을 위한 오버헤드(캐시 초기화, 인터럽트 등)가 발생한다.
- 프로세스는 각각 독립적인 메모리를 할당받았기 때문에 통신하는 것이 어렵다.

멀티 쓰레드 - 하나의 프로그램을 여러 개의 쓰레드로 구성하여 각 쓰레드가 1개의 작업을 처리하도록 하는 것

- 프로세스를 위해 자원을 할당하는 시스템콜이나 Context Switching의 오버헤드를 줄일 수 있다.
- 쓰레드는 메모리를 공유하기 때문에, 통신이 쉽고 자원을 효율적으로 사용할 수 있다.
- 하나의 쓰레드에 문제가 생기면 전체 프로세스가 영향을 받는다.
- 여러 쓰레드가 하나의 자원에 동시에 접근하는 경우 자원 공유(동기화)의 문제가 발생할 수 있다.

멀티 스레드는 멀티 프로세스보다 적은 메모리 공간을 차지하고 문맥 전환이 빠르다는 장점이 있지만, 오류로 인해 하나의 스레드가 종료되면 전체 스레드가 종료될 수 있다는 점과 동기화 문제를 안고 있다. 

반면 멀티 프로세스 방식은 하나의 프로세스가 죽더라도 다른 프로세스에는 영향을 끼치지 않고 정상적으로 수행된다는 장점이 있지만, 멀티 스레드보다 많은 메모리 공간과 CPU 시간을 차지한다는 단점이 있다. 

이 두 가지는 동시에 여러 작업을 수행한다는 점에서 같지만 적용해야 하는 시스템에 따라 적합/부적합이 구분된다.



### Context Switching

인터럽트를 발생시켜 CPU에서 실행중인 프로세스를 중단하고, 다른 프로세스를 처리하기 위한 과정이다. 

현재 실행중인 프로세스의 상태를 먼저 저장하고, 다른 프로세스를 동작시켜 작업을 처리한 후에 이전에 저장된 프로세스의 상태를 다시 복구한다. 

여기서 인터럽트란 CPU가 프로세스를 실행하고 있을 때, 입출력 하드웨어 등의 장치나 예외상황이 발생하여 처리가 필요함을 CPU에게 알리는 것을 말한다.



## 가상메모리와 페이지폴트

가상메모리는 RAM의 부족한 용량을 보완하기 위해, 각 프로그램에 실제 메모리 주소가 아닌 가상의 메모리 주소를 할당하는 방식이다.

OS는 프로세스들의 내용(페이지) 중에서 덜 중요한 것들을 하드디스크에 옮겨 놓고, 관련 정보를 페이지 테이블에 기록한다.

CPU는 프로세스를 실행하면서 페이지 테이블을 통해 페이지를 조회하는데, 실제메모리에 원하는 페이지가 없는 상황이 발생할 수 있다. 

이것을 페이지 폴트라고 하는데, 프로세스가 동작하면서 실제메모리에 필요한 데이터가 없으면 가상메모리를 통해서 해당 데이터를 가져오게 된다.

가상메모리는 하드디스크에 저장되어 있기 때문에, 페이지폴트가 발생하면 I/O에 의한 속도 저하가 발생한다.



#### 페이지 교체 알고리즘과 LRU(Least Recently Used)

페이지를 교체하는 이유는 가상메모리를 통해 조회한 페이지는 다시 사용할 가능성이 높기 때문이다.

페이지 교체를 위해서는 실제메모리에 존재하는 페이지를 가상메모리에 저장한 후에, 가상메모리에서 조회한 페이지를 실제메모리로 로드해야 한다.

어떤 실제메모리의 페이지를 가상메모리로 희생시킬 것이냐를 판단할 때 LRU를 사용한다. 실제메모리의 페이지들 중에서 가장 오랫동안 사용되지 않은 페이지를 선택하는 방식이다.



## 캐시의 지역성

캐시 메모리는 속도가 빠른 장치와 느린 장치간의 속도차에 따른 병목 현상을 줄이기 위한 범용 메모리이다. 이러한 역할을 수행하기 위해서는 CPU가 어떤 데이터를 원할 것인가를 어느 정도 예측할 수 있어야 한다. 캐시의 성능은 작은 용량의 캐시 메모리에 CPU가 이후에 참조할, 쓸모 있는 정보가 어느 정도 들어있느냐에 따라 좌우되기 때문이다.

이때 적중률을 극대화 시키기 위해 데이터 지역성의 원리를 사용한다. 지역성의 전제조건으로 프로그램은 모든 코드나 데이터를 균등하게 Access하지 않는다는 특성을 기본으로 한다. 즉, Locality란 기억 장치 내의 정보를 균일하게 Access하는 것이 아닌 어느 한 순간에 특정 부분을 집중적으로 참조하는 특성인 것이다.

이 때 데이터 지역성은 대표적으로 시간 지역성과 공간 지역성으로 나뉜다.

- 시간 지역성: 최근에 참조된 주소의 내용은 곧 다음에 다시 참조되는 특성
- 공간 지역성: 대부분의 실제 프로그램이 참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성

#### Caching line

캐시는 프로세서 가까이에 위치하면서 빈번하게 사용되는 데이터를 놔두는 장소이다. 하지만 캐시가 아무리 가까이 있더라도 찾고자 하는 데이터가 어느 곳에 저장되어 있는지 몰라 모든 데이터를 순회해야 한다면 시간이 오래 걸리게 된다.

즉, 캐시에 목적 데이터가 저장되어 있다면 바로 접근하여 출력할 수 있어야 캐시가 의미 있어진다는 것이다.

그래서 캐시에 데이터를 저장할 때 특정 자료구조를 사용하여 묶음으로 저장하게 되는데 이를 캐싱 라인이라고 한다. 데이터의 메모리 주소 등을 기록해 놓은 태그들의 묶음이다.