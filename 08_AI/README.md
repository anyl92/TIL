## ğŸ¤ì¸ê³µì§€ëŠ¥ í”„ë¡œì íŠ¸ - ì´ë¯¸ì§€ ìº¡ì…”ë‹ í™œìš© ì‹œìŠ¤í…œ

### Sub PJT 1 ì¸ê³µì§€ëŠ¥ ê¸°ì´ˆ ë° ë°ì´í„° ì „ì²˜ë¦¬



 ![python](https://img.shields.io/badge/python-3.7.6-blueviolet) ![tensorflow](https://img.shields.io/badge/tensorflow-2.0.0-ff69b4) ![keras](https://img.shields.io/badge/keras-2.2.5-critical) ![scikit-learn](https://img.shields.io/badge/scikit--learn-0.22-blue)



ë¨¼ì € venv ê°€ìƒí™˜ê²½ì„ ë§Œë“¤ê³  tensorflow ë° í•„ìš” íŒ¨í‚¤ì§€ë“¤ì„ ì„¤ì¹˜í•œë‹¤.

```bash
$ python -m venv venv
$ source venv/Scripts/activate
(venv)
$ pip install tensorflow==2.0.0 tensorflow-gpu==2.0.0
$ pip install matplotlib scikit-learn tqdm scipy numpy
```



#### Req 1. ë‹¨ìˆœ ì„ í˜• íšŒê·€ ëª¨ë¸ êµ¬í˜„

`linear_regression.py`

```python
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from models.linear_model import LinearModel
```

- tensorflow

í…ì„œí”Œë¡œìš°ëŠ” ë‹¤ì–‘í•œ ì‘ì—…ì— ëŒ€í•´ ë°ì´í„° íë¦„ í”„ë¡œê·¸ë˜ë°ì„ ìœ„í•œ ì˜¤í”ˆì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë‹¤.

ì‹¬ë³¼ë¦­ ìˆ˜í•™ ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ì, ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬ê°™ì€ ê¸°ê³„í•™ìŠµ ì‘ìš©í”„ë¡œê·¸ë¨ì—ë„ ì‚¬ìš©ëœë‹¤.



- numpy

ë„˜íŒŒì´ëŠ” í–‰ë ¬ì´ë‚˜ ì¼ë°˜ì ìœ¼ë¡œ ëŒ€ê·œëª¨ ë‹¤ì°¨ì› ë°°ì—´ì„ ì‰½ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ëŠ” íŒŒì´ì¬ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë‹¤.

ë°ì´í„° êµ¬ì¡° ì™¸ì—ë„ ìˆ˜ì¹˜ ê³„ì‚°ì„ ìœ„í•´ íš¨ìœ¨ì ìœ¼ë¡œ êµ¬í˜„ëœ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤.



- matplotlib.pyplot

íŒŒì´ì¬ì—ì„œ ë§¤íŠ¸ë©ê³¼ ìœ ì‚¬í•œ ê·¸ë˜í”„ í‘œì‹œë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë‹¤.



- models.linear_model.LinearModel

ì´ê²Œ .......... ì„ í˜• ëª¨ë¸ì„ ì“¸ ìˆ˜ ìˆê²Œ í•´ ì£¼ëŠ” ê±°ê² ì§€ .. ?



```python
# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
train_data = np.load(".\\datasets\\linear_train.npy")
test_x = np.load(".\\datasets\\linear_test_x.npy")
```

np.load()ë¼ëŠ” ëª…ë ¹ì–´ë¡œ npy, npz íŒŒì¼ì„ ì½ì–´ì™€ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.



```python
# tf í˜•ì‹ì— ë§ê²Œ ë³€í™˜
x_data = np.expand_dims(train_data[:,0], axis=1)
y_data = train_data[:,1]
```

expand_dims ... ì°¨ì›ì„ ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜.



```python
# ëª¨ë¸ ìƒì„±
model = LinearModel(num_units=1)
```



```python
# ìµœì í™” í•¨ìˆ˜, ì†ì‹¤í•¨ìˆ˜ì™€ ëª¨ë¸ ë°”ì¸ë”© (í•™ìŠµ ì¤€ë¹„)
model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
			  loss=tf.keras.losses.MSE,
			  metrics=[tf.keras.metrics.MeanSquaredError()])
```

- keras

ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ë§Œë“¤ê³  í›ˆë ¨í•˜ê¸° ìœ„í•œ ê³ ìˆ˜ì¤€ APIì´ë©° í…ì„œí”Œë¡œì˜ íŠ¹ìˆ˜ ê¸°ëŠ¥ì„ ëª¨ë‘ ì§€ì›í•œë‹¤.

ì¸µ(layer)ì„ ì¡°í•©í•˜ì—¬ ëª¨ë¸(model)ì„ ë§Œë“ ë‹¤. ëª¨ë¸ì€ ì¼ë°˜ì ìœ¼ë¡œ ì¸µì˜ ê·¸ë˜í”„ì´ë‹¤.



- optimizer

í›ˆë ¨ ê³¼ì •ì„ ì„¤ì •í•œë‹¤. Adam / SGD ê°™ì€ ì˜µí‹°ë§ˆì´ì € ê°ì²´ë¥¼ ì „ë‹¬í•œë‹¤. ë¬¸ìì—´ ì§€ì • ê°€ëŠ¥

ë°ì´í„°ì™€ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª¨ë¸ì˜ ì—…ë°ì´íŠ¸ ë°©ë²•ì„ ê²°ì •í•œë‹¤.



- loss

ìµœì í™” ê³¼ì •ì—ì„œ ìµœì†Œí™”ë  ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì„¤ì •í•œë‹¤. í‰ê· ì œê³±ì˜¤ì°¨(MSE) / 'categorical_crossentropy'/ 'binary_crossentropy' ë“±ì´ ì‚¬ìš©ëœë‹¤.

í›ˆë ¨í•˜ëŠ” ë™ì•ˆ ëª¨ë¸ì˜ ì˜¤ì°¨ë¥¼ ì¸¡ì •í•œë‹¤. ëª¨ë¸ì˜ í•™ìŠµì´ ì˜¬ë°”ë¥¸ ë°©í–¥ìœ¼ë¡œ í–¥í•˜ë„ë¡ ì´ í•¨ìˆ˜ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤.



- metrics

í›ˆë ¨ ë‹¨ê³„ì™€ í…ŒìŠ¤íŠ¸ ë‹¨ê³„ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê¸° ìœ„í•´ ì‚¬ìš©ëœë‹¤. 5.ì‹¬í™” ì˜ˆì œì—ì„œëŠ” ì˜¬ë°”ë¥´ê²Œ ë¶„ë¥˜ëœ ì´ë¯¸ì§€ì˜ ë¹„ìœ¨ì¸ ì •í™•ë„ë¥¼ ì‚¬ìš©í•œë‹¤.



```python
# ëª¨ë¸ í•™ìŠµ
model.fit(x=x_data, 
		  y=y_data, 	
		  epochs=10, 
		  batch_size=32)
```

- epochs

ì „ì²´ ì…ë ¥ ë°ì´í„°ë¥¼ í•œ ë²ˆ ìˆœíšŒí•˜ëŠ” íšŸìˆ˜ë¥¼ ë§í•œë‹¤. (ì‘ì€ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ìˆ˜í–‰ëœë‹¤)

epochs=40 ì´ë¼ë©´ ì „ì²´ ë°ì´í„°ë¥¼ 40ë²ˆ ì‚¬ìš©í•´ì„œ í•™ìŠµì„ ê±°ì¹œë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.

epochê°’ì´ ë„ˆë¬´ ì‘ë‹¤ë©´ underfittingì´ ë„ˆë¬´ í¬ë‹¤ë©´ overfittingì´ ë°œìƒí™œ í™•ë¥ ì´ ë†’ë‹¤.



- batch_size

ë„˜íŒŒì´ ë°ì´í„°ë¥¼ ì „ë‹¬í•˜ë©´ ëª¨ë¸ì€ ë°ì´í„°ë¥¼ ì‘ì€ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ê³  í›ˆë ¨ ê³¼ì •ì—ì„œ ì´ ë°°ì¹˜ë¥¼ ìˆœíšŒí•œë‹¤. 

í•œ ë²ˆì˜ batchë§ˆë‹¤ ì£¼ëŠ” ë°ì´í„° ìƒ˜í”Œì˜ sizeë¥¼ ë§í•œë‹¤. batch(=mini-batch)ëŠ” ë‚˜ëˆ ì§„ ë°ì´í„° ì…‹ì„ ëœ»í•¨



- iteration

epochë¥¼ ë‚˜ëˆ„ì–´ ì‹¤í–‰í•˜ëŠ” íšŸìˆ˜ë¥¼ ë§í•œë‹¤.

ë©”ëª¨ë¦¬ì˜ í•œê³„ì™€ ì†ë„ ì €í•˜ ë•Œë¬¸ì— ëŒ€ë¶€ë¶„ì˜ ê²½ìš°ì—ëŠ” í•œ ë²ˆì˜ epochì—ì„œ ëª¨ë“  ë°ì´í„°ë¥¼ í•œêº¼ë²ˆì— ì‚¬ìš©í•  ìˆ˜ ì—†ë‹¤. ê·¸ë˜ì„œ iteration ìˆ˜ ë§Œí¼ ë‚˜ëˆ„ì–´ ì£¼ê²Œ ëœë‹¤. ì´ ë•Œì˜ ë°ì´í„° ì‚¬ì´ì¦ˆê°€ batch_sizeì´ë‹¤.

![fit](./summary/1-2_model fit.png)



```python
# ëª¨ë¸ í…ŒìŠ¤íŠ¸
prediction = model.predict(x=test_x,
    					   batch_size=None)
```

- predict

ì£¼ì–´ì§„ ë°ì´í„°ë¡œ ì¶”ë¡  ëª¨ë“œì—ì„œ ë§ˆì§€ë§‰ ì¸µì˜ ì¶œë ¥ì„ ì˜ˆì¸¡í•˜ì—¬ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë°˜í™˜í•œë‹¤.



```python
# ê²°ê³¼ ì‹œê°í™”
plt.scatter(x_data, y_data, s=5, label="train data")
plt.scatter(test_x,prediction,s=5,label="prediction data")
plt.show()
```

scatter()ë¡œ ê·¸ë¦¬ë©°

show()ë¡œ ì¶œë ¥

legend() : ë²”ì£¼

xlim(), ylim() : ë²”ìœ„



```python
# ëª¨ë¸ ì •ë¦¬
model.summary()
```



ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ ê·¸ë˜í”„ê°€ ë‚˜ì˜¨ë‹¤

![graph](./summary/1-1_linear regression result.png)





#### Req 2. ì´ë¯¸ì§€ ìº¡ì…”ë‹ Configuration

- ì´ë¯¸ì§€ ìº¡ì…”ë‹ì´ë€?

Captionì´ë€ ì‚¬ì§„ì´ë‚˜ ì‚½í™”ì— ë¶™ì¸ ì„¤ëª…ì„ ì˜ë¯¸í•œë‹¤. ì»´í“¨í„° ë¹„ì „ì—ì„œ image captioningì´ë€ ì»´í“¨í„°ê°€ ì‚¬ì§„ì„ ë³´ê³  ì ì ˆí•œ ì„¤ëª…ì„ ìë™ìœ¼ë¡œ ë¶™ì´ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. ë”°ë¼ì„œ image captioning ì•Œê³ ë¦¬ì¦˜ì˜ ì…ë ¥ì€ ì´ë¯¸ì§€ê°€ ë˜ê³ , ì¶œë ¥ì€ ë¬¸ì¥ì´ ëœë‹¤.



ì´ë¯¸ì§€ ìº¡ì…”ë‹ì„ ì‹œì‘í•˜ê¸° ì „ì—, íŒŒì´ì¬ ë‚´ì¥ í•¨ìˆ˜ì¸ argparseë¥¼ ì´ìš©í•´ í•¨ìˆ˜ ì‹¤í–‰ ì‹œ ì¸ì ê°’ì„ ì¤„ ìˆ˜ ìˆê²Œ êµ¬ì„±í•˜ë ¤ê³  í•œë‹¤. 

2-1 `config.py` íŒŒì¼ êµ¬í˜„

```python
import argparse

parser = argparse.ArgumentParser()
parser.add_argument('--caption_file_path', type=str, default='./datasets/captions.csv')
parser.add_argument('--image_file_path', type=str, default='./datasets/images/')
parser.add_argument('--saved_dataset', type=str, default='test')
parser.add_argument('--do_sampling', type=str, default='10')

config = parser.parse_args()
```

ëª¨ë¸ êµ¬í˜„ì— í•„ìš”í•œ ì„¸íŒ… ê°’ë“¤ì´ ì €ì¥ë¨. íŒŒì¼ ê²½ë¡œ, ì…ë ¥ ë³€ìˆ˜ ë“±ì„ ì§€ì •í•´ì¤„ ìˆ˜ ìˆë‹¤.



2-2 ì„¸íŒ… ê°’ ì €ì¥

configuration ë³€ìˆ˜ë“¤ì€ ì¶”í›„ ë‹¤ì–‘í•˜ê²Œ ë°”ê¿”ê°€ë©° ì‹¤í—˜ë˜ê¸° ë•Œë¬¸ì— `train.py`ë¥¼ ì‹¤í–‰í•  ë•Œë§ˆë‹¤ ë‹¹ì‹œì˜ ì„¸íŒ… ê°’ë“¤ì„ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„í•œë‹¤.

`utils.py`

```python
import matplotlib.pyplot as plt
from matplotlib.image import imread
from config import config
from datetime import datetime
import csv

# Req. 2-2	ì„¸íŒ… ê°’ ì €ì¥
def save_config():
	log = open('log_config.csv', 'a', newline='')
	csvwriter = csv.writer(log, delimiter=',')
	csvwriter.writerow([datetime.now(), config.caption_file_path, config.image_file_path, config.do_sampling, config.saved_dataset])
	log.close()
```





#### Req 3. ì´ë¯¸ì§€ ìº¡ì…”ë‹ ë°ì´í„° ì „ì²˜ë¦¬

`preprocess.py`

```python
import csv
import numpy as np
from sklearn.model_selection import train_test_split
```



3-1 ì´ë¯¸ì§€ ê²½ë¡œ ë° ìº¡ì…˜ ë¶ˆëŸ¬ì˜¤ê¸°

```python
def get_path_caption():
    csv_data = np.loadtxt('./datasets/captions.csv', delimiter='|', dtype=np.str)
    csv_data = np.delete(csv_data, 0, 0)

    image_name = []
    comment = []
    for row in csv_data:
        img = row[0].strip('\"')
        image_name.append(img)
        comm = row[-1].strip(',').strip()
        comment.append(comm)
        
    return [image_name, comment]
```

np.loadtxt í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ êµ¬ë¶„ìë¥¼ '|'ë¡œ, dtypeì„ np.strìœ¼ë¡œ ë°›ì•„ì™”ë‹¤.

csv_dataì—ì„œ headerë¥¼ ë¹¼ê³  ì‹¶ì–´ ì²˜ìŒì—” ë°°ì—´ì²˜ëŸ¼ ìƒê°í•˜ê³  popì„ í–ˆë‹¤ê°€ ì—ëŸ¬ ë°œìƒ

np.delete(arr, obj(row or column number), axis) ë¡œ 0ì¸ë±ìŠ¤ ë°ì´í„° ì œê±°

image_name, comment ë°°ì—´ì— ê°ê° append í–ˆë‹¤.

imgì—ëŠ” ", commentì—ëŠ” ',,,,,,,' ì™€ ê³µë°±ì´ ë¶™ì–´ ë‚˜ì™€ì„œ strip í•´ ì£¼ì—ˆë‹¤.



`ë”•ì…”ë„ˆë¦¬ë¡œëŠ” ì´ë ‡ê²Œ í•´ ë³´ì•˜ë‹¤.

```python
	result = {}
    for row in csv_data:
        comment = row[-1].strip(',').strip()
        if bool(result.get(row[0])) == False:
            result[row[0]] = [comment]
        else:
            result[row[0]].append(comment)
    return result
```

![3-2.get_path_caption_dict.png](./summary/3-1.get_path_caption_dict.png)



3-2 ì „ì²´ ë°ì´í„°ì…‹ì„ ë¶„ë¦¬í•´ ì €ì¥í•˜ê¸°

- ì „ì²´ ë°ì´í„°ë¥¼ í•™ìŠµìš© ë° í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ë¡œ ë¶„ë¦¬í•˜ëŠ” ì´ìœ 

ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì— train ë°ì´í„°ë¥¼ 100% í•™ìŠµì‹œí‚¨ í›„ test ë°ì´í„°ì— ëª¨ë¸ì„ ì ìš©í–ˆì„ ë•Œ ì„±ëŠ¥ì´ ìƒê°ë³´ë‹¤ ì•ˆ ë‚˜ì˜¤ëŠ” ê²½ìš°ê°€ ë§ë‹¤. ì´ëŸ° í˜„ìƒì„ overfitting ë˜ì—ˆë‹¤ ë¼ê³  í•œë‹¤. ì¦‰, ëª¨ë¸ì´ ë‚´ê°€ ê°€ì§„ í•™ìŠµ ë°ì´í„°ì— ê³¼ì í•©ë˜ì–´, ë‹¤ë¥¸ ì¼€ì´ìŠ¤ì—ëŠ” ì˜ˆì¸¡ìœ¨ì´ ë–¨ì–´ì§€ëŠ” ê²ƒì´ë‹¤. ì´ëŸ° overfittingì„ ë°©ì§€í•˜ëŠ” ê²ƒì´ ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ì„ ë”°ì ¸ë³´ì•˜ì„ ë•Œ ë§¤ìš° ì¤‘ìš”í•œ í”„ë¡œì„¸ìŠ¤ì´ë‹¤.



```python
def dataset_split_save(dataset):
    train_x, test_x, train_y, test_y = train_test_split(dataset[0], dataset[1], shuffle=False)
```

train_test_split(array*, test_size, train_size, random_state, shuffle, stratify)

ë°ì´í„°ë“¤ì„ í•„ìˆ˜ ì¸ì ê°’ìœ¼ë¡œ ë°›ëŠ”ë‹¤. list, arrays, matrics, dataframe ë“± ë‹¤ì–‘í•œ í˜•íƒœë¥¼ í¬í•¨í•œë‹¤. í´ë˜ìŠ¤ ê°’ì„ í¬í•¨í•˜ì—¬ í•˜ë‚˜ì˜ ë°ì´í„°ë¡œ ë°›ê±°ë‚˜ í´ë˜ìŠ¤ ê°’ì„ ë¶„ë¦¬í•´ì„œ ë‘ ê°œì˜ ë°ì´í„°ë¡œë„ ë°›ì„ ìˆ˜ ìˆë‹¤.

test_sizeëŠ” float, int, None ê°’ì´ë‹¤. floatì€ ì „ì²´ ë°ì´í„° ì…‹ì—ì„œ testsetì˜ ë¹„ìœ¨ì„ ì˜ë¯¸í•œë‹¤. intëŠ” ë°ì´í„° ê°œìˆ˜ë¥¼ ì˜ë¯¸í•œë‹¤. ê¸°ë³¸ ê°’ì€ 0.25ì´ë‹¤.

train_sizeëŠ” test_sizeì™€ ê°™ì§€ë§Œ ì „ì²´ ë°ì´í„° ì…‹ì—ì„œ trainsetì˜ ì–‘ì„ ì˜ë¯¸í•œë‹¤. ê¸°ë³¸ ê°’ì€ Noneì´ë‹¤.

random_stateëŠ” int, randomstate instance, None ê°’ì´ë‹¤. intëŠ” ìˆ«ìë¥¼ ëœë¤í•˜ê²Œ ìƒì„±í•  ë•Œ ì‚¬ìš©ë˜ëŠ” seed ìˆ«ìë¡œ ì‚¬ìš©ëœë‹¤. Noneì„ ì…ë ¥í•˜ë©´ np.randomì—ì„œ ì œê³µí•˜ëŠ” random number generatorê°€ ì‚¬ìš©ëœë‹¤.

shuffleì€ bool ê°’ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë¶„ë¦¬í•˜ê¸° ì „ì— ë°ì´í„°ë¥¼ ì„ì„ ê²ƒì¸ì§€ ì§€ì •í•˜ë©° ê¸°ë³¸ê°’ì€ Trueì´ë‹¤.

stratifyëŠ” í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„°ë“¤ì´ ì›ë˜ì˜ input datasetì˜ í´ë˜ìŠ¤ì™€ ê°™ì€ ë¹„ìœ¨ì„ ê°€ì§€ë„ë¡ í•  ê²ƒì¸ì§€ ì§€ì •í•œë‹¤. 



```python
# print(len(train_x), train_x[:5], '\n')
# print(len(test_x), test_x[:5], '\n')
# print(len(train_y), train_y[:5], '\n')
# print(len(test_y), test_y[:5], '\n')
```

`shuffle=True` ì¼ ë•Œ (ê¸°ë³¸ê°’)

![3-2.dataset_split_save.png](./summary/3-2.dataset_split_save.png)

`shuffle=False` ë¥¼ ì£¼ë©´ ì•„ë˜ì™€ ê°™ë‹¤

![3-3.dataset_split_save_noshuffle.png](./summary/3-3.dataset_split_save_noshuffle.png)



```python
np.savez('./datasets/test_dataset.npz', x=test_x, y=test_y)
np.savez('./datasets/train_dataset.npz', x=train_x, y=train_y)
```

npyëŠ” í•˜ë‚˜ì˜ ë°ì´í„°ë¥¼ ì €ì¥í•  ë•Œ, npzëŠ” ë³µìˆ˜ì˜ íŒŒì¼ì„ key-value pairí˜•íƒœë¡œ ì €ì¥í•  ë•Œ

ì´ë ‡ê²Œ ì €ì¥í•˜ë©´ binaryí˜•íƒœë¡œ ì €ì¥ì´ ë˜ì–´ì„œ í›¨ì”¬ ì ì€ ìš©ëŸ‰ì„ ì°¨ì§€í•œë‹¤.



3-3 ì €ì¥ëœ ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°

ì²˜ìŒì— ëª…ì„¸ë¥¼ ì˜ëª» ì´í•´í•˜ê³  ì´ëŸ° ê±¸ ì§°ë‹¤...

```python
def get_data_file(inp):
    if inp != 'train_x' and inp != 'test_x' and inp != 'train_y' and inp != 'test_y':
        return print('ì œëŒ€ë¡œ ì…ë ¥í•˜ì…ˆ')
    if inp[:4] == 'test':
        data = np.load('../datasets/test_dataset.npz')
        if inp[-1] == 'x':
            return print(data['x'])
        else:
            return print(data['y'])
    else:
        data = np.load('../datasets/train_dataset.npz')
        if inp[-1] == 'x':
            return print(data['x'])
        else:
            return print(data['y'])
```

ì•„ë˜ ì½”ë“œë¡œ  ìˆ˜ì •!

```python
def get_data_file(inp):
    if inp != 'train' and inp != 'test':
        return print('ì œëŒ€ë¡œ ì…ë ¥í•˜ì…ˆ')
    data = np.load(f'./datasets/{inp}_dataset.npz')

    result = {}
    img = data['x']
    comment = data['y']
    img_stan = img[0]
    idx = 1
    del_list = [0]

    while img != []:
        if idx >= len(img):
            break
        if img[idx] == img_stan:
            del_list.append(idx)
            idx += 1
        else:
            del_list.append(idx)
            com_list = []
            for com in comment[:idx]:
                com_list.append(com)
            result[img[idx]] = com_list
            img = np.delete(img, del_list, 0)
            comment = np.delete(comment, del_list, 0)
            img_stan = img[0]
            idx = 1
            del_list = [0]
    return result
```

inpê°’ìœ¼ë¡œ ì–´ë–¤ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ì§€ ì •í•  ìˆ˜ ìˆê²Œ í–ˆê³ 

ì´ë¯¸ì§€ ì´ë¦„ì— ì—¬ëŸ¬ ìº¡ì…˜ì´ ë“¤ì–´ê°€ê¸° ë•Œë¬¸ì— dict í˜•íƒœë¡œ keyì— name, valueì— captionì„ listë¡œ ë„£ì–´ returní–ˆë‹¤.

test_datasetì˜ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

![3-4.get_data_file_dict.png](./summary/3-4.get_data_file_dict.png)



3-4 ë°ì´í„° ìƒ˜í”Œë§

```python
def sampling_data(rate):
    img, com = get_path_caption()
    
    dataset = []
    for i in range(len(img)):
        dataset.append(img[i] + ', ' + com[i])
    
    return np.random.choice(dataset, size=int(len(img) * float(rate) / 100), replace=False).tolist()
```

ì²˜ìŒì— ë°›ì•„ì™”ë˜ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•œë‹¤. random.choiceë¥¼ ì“°ê¸° ìœ„í•´ì„œëŠ” ì°¨ì›ì„ ì—†ì•¤ë‹¤.



ì‹¤í–‰ ì½”ë“œ ! ì´ê²ƒë„ `train.py`ì˜ ì¡´ì¬ë¥¼ ì•Œê¸° ì „ ......^~^

```python
dataset_split_save(get_path_caption())
print('train, test')
res = get_data_file(input())
print('size?')
sampling_data(input())
```





#### Req 4. ì´ë¯¸ì§€ì™€ ìº¡ì…˜ ì‹œê°í™”

ì´ë¯¸ì§€ íŒŒì¼ê³¼ ìº¡ì…˜ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ì´ë¥¼ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„í•œë‹¤.

ì´ í”„ë¡œì íŠ¸ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ì´ì œì„œì•¼ ì œëŒ€ë¡œ ì•Œê²Œ ëê³ , ë˜ `config.py`ë¥¼ ì‚¬ìš©í•´ì„œ ë¯¸ë¦¬ ì €ì¥í•´ë†“ì€ ì„¤ì •ì„ ì‚¬ìš©í•´ë³´ê²Œ ë˜ì–´ ì½”ë“œ ìˆ˜ì •ì„ ì¢€ í–ˆë‹¤.!

`train.py`

```python
from config import config
from data import preprocess
from utils import utils

# config ì €ì¥
utils.save_config()

# ì´ë¯¸ì§€ ê²½ë¡œ ë° ìº¡ì…˜ ë¶ˆëŸ¬ì˜¤ê¸°
image_info = preprocess.get_path_caption()

# ì „ì²´ ë°ì´í„°ì…‹ì„ ë¶„ë¦¬í•´ ì €ì¥í•˜ê¸°
preprocess.dataset_split_save(image_info)

# ì €ì¥ëœ ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
dataset_dict = preprocess.get_data_file(config.saved_dataset)

# ë°ì´í„° ìƒ˜í”Œë§
dataset_sampling = preprocess.sampling_data(config.do_sampling)

# ì´ë¯¸ì§€ì™€ ìº¡ì…˜ ì‹œê°í™” í•˜ê¸°
utils.visualize_img_caption(dataset_sampling)
```

```python
def visualize_img_caption(dataset):
	img, com = '', ''
	for data in dataset:
		for s in range(len(data)):
			if data[s] == '|':
				img = data[:s]
				com = data[s+1:]
                
		addr = imread(config.image_file_path + img)
		plt.imshow(addr)
		plt.title(f'<start>{com}<end>')
		plt.show()
```

ìƒ˜í”Œë§ ëœ string ë°ì´í„°ì—ì„œ '|' ë¡œ êµ¬ë¶„ë˜ì–´ ìˆëŠ” ì´ë¯¸ì§€ì™€ ìº¡ì…˜ì„ ë¶„ë¦¬í•˜ì—¬ í•˜ë‚˜ì”© ë°›ì•„ì˜¨ë‹¤.

plt.imshow()ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì¶œë ¥í•  ìˆ˜ ìˆë‹¤. (pip install pillow)

![4-1.img_plot.png](./summary/4-1.img_plot.png)





#### Req 5.Fashion MNIST ë¶„ë¥˜ ëª¨ë¸ êµ¬í˜„

5-1 Fashion MNIST ë°ì´í„° ë‹¤ìš´ ë° ì‹œê°í™”

```python
from __future__ import absolute_import, division, print_function, unicode_literals, unicode_literals

import tensorflow as tf
from tensorflow import keras

import numpy as np
import matplotlib.pyplot as plt

print(tf.__version__)
```

    2.0.0

```python
# íŒ¨ì…˜ MNIST ë°ì´í„°ì…‹ ì„í¬íŠ¸
fashion_mnist = keras.datasets.fashion_mnist
# load_data() í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ë©´ ì•„ë˜ 4ê°œì˜ ë„˜íŒŒì´ ë°°ì—´ì´ ë°˜í™˜ë¨
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
```


```python
# ë°ì´í„°ì…‹ì— í´ë˜ìŠ¤ ì´ë¦„ì´ ë“¤ì–´ìˆì§€ ì•Šê¸° ë•Œë¬¸ì— ë³„ë„ì˜ ë³€ìˆ˜ë¥¼ ë§Œë“¤ì–´ ì§€ì •
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 
              'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
```


```python
test_images.shape
```


    (10000, 28, 28)


```python
plt.figure()
plt.imshow(train_images[0])
plt.colorbar()
plt.grid(False)
plt.show()
```


![png](./summary/output_6_0.png)

```python
# í”½ì…€ ê°’ì˜ ë²”ìœ„ê°€ 0-255ì„. ì´ ê°’ì˜ ë²”ìœ„ë¥¼ 0-1 ì‚¬ì´ë¡œ ì¡°ì •í•˜ê² ìŒ.
train_images = train_images / 255.0
test_images = test_images / 255.0
```


```python
# í›ˆë ¨ ë°ì´í„° í¬ë§·ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ê³  ë„¤íŠ¸ì›Œí¬ êµ¬ì„±ê³¼ í›ˆë ¨í•  ì¤€ë¹„
plt.figure(figsize=(10, 10))
for i in range(25):
    plt.subplot(5, 5, i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i]])
plt.show()

```


![png](./summary/output_8_0.png)



5-2 ì¸ê³µì‹ ê²½ë§ êµ¬í˜„ ë° ì»´íŒŒì¼

  ëª¨ë¸ êµ¬ì„±, ì¸µ ì„¤ì •

- ì‹ ê²½ë§ì˜ êµ¬ì„± ìš”ì†ŒëŠ” ì¸µ(layer)ì´ë‹¤. ì¸µì€ ì£¼ì…ëœ ë°ì´í„°ì—ì„œ í‘œí˜„ì„ ì¶”ì¶œí•œë‹¤. ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° ë” ì˜ë¯¸ìˆëŠ” í‘œí˜„ì´ ì¶”ì¶œë  ê²ƒì´ë‹¤.
- ëŒ€ë¶€ë¶„ì˜ ë”¥ëŸ¬ë‹ì€ ê°„ë‹¨í•œ ì¸µì„ ì—°ê²°í•˜ì—¬ êµ¬ì„±ëœë‹¤.
- tf.keras.layers.Dense ì™€ ê°™ì€ ì¸µë“¤ì˜ ê°€ì¤‘ì¹˜ëŠ” í›ˆë ¨í•˜ëŠ” ë™ì•ˆ í•™ìŠµëœë‹¤.


```python
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])
```

ì´ ë„¤íŠ¸ì›Œí¬ì˜ ì²« ë²ˆì§¸ ì¸µì¸ tf.keras.layers.Flatten ì€ 2ì°¨ì› ë°°ì—´(28\*28)ì˜ ì´ë¯¸ì§€ í¬ë§·ì„ 28*28=784 ì˜ 1ì°¨ì› ë°°ì—´ë¡œ ë³€í™˜í•œë‹¤. ì´ ì¸µì€ ì´ë¯¸ì§€ì— ìˆëŠ” í”½ì…€ì˜ í–‰ì„ í¼ì³ì„œ ì¼ë ¬ë¡œ ëŠ˜ë¦°ë‹¤. ì´ ì¸µì—ëŠ” í•™ìŠµë˜ëŠ” ê°€ì¤‘ì¹˜ê°€ ì—†ê³  ë°ì´í„° ë³€í™˜ë§Œ í•œë‹¤.
í”½ì…€ì„ í¼ì¹œ í›„ì— ë‘ ê°œì˜ tf.keras.layers.Dense ì¸µì´ ì—°ì†ë˜ì–´ ì—°ê²°ëœë‹¤. ì´ ì¸µì„ ë°€ì§‘ ì—°ê²°(densely-connected) ë˜ëŠ” ì™„ì „ ì—°ê²°(fully-connected) ì¸µì´ë¼ê³  ë¶€ë¥¸ë‹¤.
ì²« ë²ˆì§¸ Dense ì¸µì€ 128ê°œì˜ ë…¸ë“œ(ë˜ëŠ” ë‰´ëŸ°)ë¥¼ ê°€ì§„ë‹¤. ë‘ ë²ˆì§¸(ë§ˆì§€ë§‰) ì¸µì€ 10ê°œì˜ ë…¸ë“œì˜ ì†Œí”„íŠ¸ë§¥ìŠ¤ì¸µì´ë‹¤. ì´ ì¸µì€ 10ê°œì˜ í™•ë¥ ì„ ë°˜í™˜í•˜ê³  ë°˜í™˜ëœ ê°’ì˜ ì „ì²´ í•©ì€ 1ì´ë‹¤. ê° ë…¸ë“œëŠ” í˜„ì¬ ì´ë¯¸ì§€ê°€ 10ê°œ í´ë˜ìŠ¤ ì¤‘ í•˜ë‚˜ì— ì†í•  í™•ë¥ ì„ ì¶œë ¥í•œë‹¤.


```python
# ëª¨ë¸ ì»´íŒŒì¼ : ëª¨ë¸ì„ í›ˆë ¨í•˜ê¸° ì „ì— í•„ìš”í•œ ì„¤ì •
model.compile(optimizer='adam',
             loss='sparse_categorical_crossentropy',
             metrics=['accuracy'])
```



5-3 ëª¨ë¸ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸

  ëª¨ë¸ í›ˆë ¨

1. í›ˆë ¨ ë°ì´í„°ë¥¼ ëª¨ë¸ì— ì£¼ì…í•œë‹¤. train_images, train_labels
2. ëª¨ë¸ì´ ì´ë¯¸ì§€ì™€ ë ˆì´ë¸”ì„ ë§¤í•‘í•˜ëŠ” ë°©ë²•ì„ ë°°ìš´ë‹¤.
3. í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ëŒ€í•œ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ë§Œë“ ë‹¤. test_images ë°°ì—´. ì´ ì˜ˆì¸¡ì´ test_labels ë°°ì—´ì˜ ë ˆì´ë¸”ê³¼ ë§ëŠ”ì§€ í™•ì¸í•œë‹¤.


```python
model.fit(train_images, train_labels, epochs=10)
```

    Train on 60000 samples
    Epoch 1/10
    60000/60000 [==============================] - 3s 54us/sample - loss: 0.1962 - accuracy: 0.9262
    Epoch 2/10
    60000/60000 [==============================] - 3s 55us/sample - loss: 0.1922 - accuracy: 0.9276
    Epoch 3/10
    60000/60000 [==============================] - 3s 57us/sample - loss: 0.1892 - accuracy: 0.9286
    Epoch 4/10
    60000/60000 [==============================] - 3s 54us/sample - loss: 0.1841 - accuracy: 0.9297
    Epoch 5/10
    60000/60000 [==============================] - 3s 55us/sample - loss: 0.1792 - accuracy: 0.9322
    Epoch 6/10
    60000/60000 [==============================] - 3s 54us/sample - loss: 0.1747 - accuracy: 0.9337
    Epoch 7/10
    60000/60000 [==============================] - 3s 54us/sample - loss: 0.1712 - accuracy: 0.9352
    Epoch 8/10
    60000/60000 [==============================] - 3s 54us/sample - loss: 0.1678 - accuracy: 0.9364
    Epoch 9/10
    60000/60000 [==============================] - 3s 54us/sample - loss: 0.1639 - accuracy: 0.9373
    Epoch 10/10
    60000/60000 [==============================] - 5s 78us/sample - loss: 0.1586 - accuracy: 0.9414
    
    <tensorflow.python.keras.callbacks.History at 0x21b26ef3788>

- epochs 5ì¼ ë•Œ í›ˆë ¨ ì„¸íŠ¸ì—ì„œ ì•½ 0.88 ì •ë„ì˜ ì •í™•ë„ ë‹¬ì„±
- epochs 10ì¼ ë•Œ í›ˆë ¨ ì„¸íŠ¸ì—ì„œ ì•½ 0.92 ì •ë„ì˜ ì •í™•ë„ ë‹¬ì„±


```python
# ì •í™•ë„ í‰ê°€ : ê·¸ ë‹¤ìŒ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•œë‹¤.
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
print('í…ŒìŠ¤íŠ¸ ì •í™•ë„: ', test_acc)
```

    10000/1 - 0s - loss: 0.2639 - accuracy: 0.8884
    í…ŒìŠ¤íŠ¸ ì •í™•ë„:  0.8884


- í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ì •í™•ë„ê°€ í›ˆë ¨ ì„¸íŠ¸ì˜ ì •í™•ë„ë³´ë‹¤ ì¡°ê¸ˆ ë‚®ë‹¤. í›ˆë ¨ ì„¸íŠ¸ì˜ ì •í™•ë„ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ì •í™•ë„ ì‚¬ì´ì˜ ì°¨ì´ëŠ” overfitting ë•Œë¬¸ì´ë‹¤.



5-4 í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì‹œê°í™”


```python
# ì˜ˆì¸¡ ë§Œë“¤ê¸° : í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì— ëŒ€í•œ ì˜ˆì¸¡ ë§Œë“¤ê¸°
predictions = model.predict(test_images)
```


```python
# í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ìˆëŠ” ê° ì´ë¯¸ì§€ì˜ ë ˆì´ë¸”ì„ ì˜ˆì¸¡í•œë‹¤. ì²« ë²ˆì§¸ ì˜ˆì¸¡ í™•ì¸
predictions[0]
```


    array([1.7601879e-13, 8.5432294e-15, 4.7925706e-16, 4.7869198e-18,
           6.7109355e-13, 2.1202037e-05, 1.6984966e-13, 3.3402473e-03,
           2.9903163e-13, 9.9663854e-01], dtype=float32)

- 10ê°œì˜ ì˜· í’ˆëª©ì— ìƒì‘í•˜ëŠ” ëª¨ë¸ì˜ ì‹ ë¢°ë„ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.


```python
# ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ë¥¼ ê°€ì§„ ë ˆì´ë¸” ì°¾ê¸°
np.argmax(predictions[0])
```


    9

- ì•µí´ ë¶€ì¸ (class_name[9])ë¼ê³  ê°€ì¥ í™•ì‹ í•˜ê³  ìˆë‹¤.


```python
# ê°’ì´ ë§ëŠ”ì§€ í…ŒìŠ¤íŠ¸ ë ˆì´ë¸” í™•ì¸
test_labels[0]
```


    9


```python
# 10ê°œ í´ë˜ìŠ¤ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ê·¸ë˜í”„ë¡œ í‘œí˜„í•˜ê¸°
def plot_image(i, predictions_array, true_label, img):
    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])

    plt.imshow(img, cmap=plt.cm.binary)

    predicted_label = np.argmax(predictions_array)
    if predicted_label == true_label:
        color = 'blue'
    else:
        color = 'red'

    plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                                100*np.max(predictions_array),
                                class_names[true_label]),
                                color=color)

def plot_value_array(i, predictions_array, true_label):
    predictions_array, true_label = predictions_array[i], true_label[i]
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])
    thisplot = plt.bar(range(10), predictions_array, color="#777777")
    plt.ylim([0, 1])
    predicted_label = np.argmax(predictions_array)

    thisplot[predicted_label].set_color('red')
    thisplot[true_label].set_color('blue')
```


```python
i = 0
plt.figure(figsize=(6,3))
plt.subplot(1,2,1)
plot_image(i, predictions, test_labels, test_images)
plt.subplot(1,2,2)
plot_value_array(i, predictions,  test_labels)
plt.show()
```


![png](./summary/output_24_0.png)

```python
i = 12
plt.figure(figsize=(6,3))
plt.subplot(1,2,1)
plot_image(i, predictions, test_labels, test_images)
plt.subplot(1,2,2)
plot_value_array(i, predictions,  test_labels)
plt.show()
```


![png](./summary/output_25_0.png)

- ì˜ëª» ì˜ˆì¸¡í•˜ê³  ìˆë‹¤. ê·¸ëŸ°ë° í•™ìŠµì„ ë” ì‹œì¼œë„ ê²°ê³¼ê°€ ë™ì¼í•˜ë‹¤...

```python
# ì²˜ìŒ X ê°œì˜ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì™€ ì˜ˆì¸¡ ë ˆì´ë¸”, ì§„ì§œ ë ˆì´ë¸”ì„ ì¶œë ¥í•©ë‹ˆë‹¤
# ì˜¬ë°”ë¥¸ ì˜ˆì¸¡ì€ íŒŒë‘ìƒ‰ìœ¼ë¡œ ì˜ëª»ëœ ì˜ˆì¸¡ì€ ë¹¨ê°•ìƒ‰ìœ¼ë¡œ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤
num_rows = 5
num_cols = 3
num_images = num_rows*num_cols
plt.figure(figsize=(2*2*num_cols, 2*num_rows))
for i in range(num_images):
  plt.subplot(num_rows, 2*num_cols, 2*i+1)
  plot_image(i, predictions, test_labels, test_images)
  plt.subplot(num_rows, 2*num_cols, 2*i+2)
  plot_value_array(i, predictions, test_labels)
plt.show()
```


![png](./summary/output_26_0.png)

```python
# í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ì´ë¯¸ì§€ í•˜ë‚˜ë¥¼ ì„ íƒí•œë‹¤
img = test_images[0]
print(img.shape)
```

    (28, 28)

```python
# tf.keras ëª¨ë¸ì€ í•œ ë²ˆì— ìƒ˜í”Œì˜ ë¬¶ìŒ ë˜ëŠ” ë°°ì¹˜ë¡œ ì˜ˆì¸¡ì„ ë§Œë“œëŠ”ë° ìµœì í™”ë˜ì–´ìˆìŒ
# í•˜ë‚˜ì˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•  ë•Œì—ë„ 2ì°¨ì› ë°°ì—´ë¡œ ë§Œë“¤ì–´ì•¼ í•œë‹¤.
img = (np.expand_dims(img, axis=0))
print(img.shape)
```

    (1, 28, 28)

```python
# ì´ë¯¸ì§€ì˜ ì˜ˆì¸¡ì„ ë§Œë“ ë‹¤
predictions_single = model.predict(img)
print(predictions_single)
```

    [[1.7601845e-13 8.5431963e-15 4.7925706e-16 4.7869016e-18 6.7109355e-13
      2.1202099e-05 1.6984999e-13 3.3402473e-03 2.9903163e-13 9.9663854e-01]]

```python
plot_value_array(0, predictions_single, test_labels)
_ = plt.xticks(range(10), class_names, rotation=45)
```


![png](./summary/output_30_0.png)

```python
np.argmax(predictions_single[0])
```


    9

