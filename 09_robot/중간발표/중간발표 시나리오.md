6/1 15:30 중간 발표회



- 사용자 시나리오(서비스적 전체적 플로우 설명)
- 계획안 얘기해줌. 부가적으로 사용 Tool의 사용이유를 밝히며 알려줌 (우리가 이렇게 짜임새 있게 만들고 있다!)
- 현재 진행상황 된거 (프로젝트 자체 결과를 보여주고)
- 진행되었던 마일스톤, (번다운차트, 지라, 프로젝트 진행 과정을 시각적으로 보여줄것이 없어서 ㅃㅂ)
- 앞으로 어떻게 완성될것인지 마일스톤+a





라즈베리파이랑 arm을 따로쓰는 이유는 라즈베리파이에 걸리는 부하를 분산시키기 위해서 

그리고 nvidia는 카메라 연결해서 유저식별 서비스를 접목시키기 위해서

따로 구분



---

2조 발표를 맡은 안유림입니다. 저희 부릉부릉 조는 자율주행을 이용한 안내 로봇을 제작하고 있습니다.

먼저 서비스 소개 후, 빅스비와 로봇의 진행 상황과 향후 계획 순으로 발표를 진행하겠습니다.

발표에 앞서, PPT 진행 중 내장된 소리의 볼륨이 클 수 있으니 조정을 부탁드립니다.



여러분, 멀티캠퍼스에 처음 왔었을 때가 기억 나시나요?

여기, 오픽 시험을 보러 멀티캠퍼스를 첫 방문한 장현진님이 서 있네요.

'건물이 크네..' 들어간다 '오픽 시험장이 어디지? 검색 해야 겠다.' 

띠띠- 저런...

검색하지 않아도 누군가 내 목적지까지 데려다 주면 어떨까요? 그래서 준비했습니다. 뚜둔!

바로 저희 부릉부릉 안내 로봇 서비스! 

음성인식을 기반으로 사용자 요청에 따라 건물 내에서 자율주행하며 안내를 해 주는 로봇입니다. 로봇의 LCD 화면과 사용자 스마트폰의 빅스비로 로봇을 사용할 수 있습니다.

지금부터 사용 방법을 소개드리겠습니다.



먼저 유저에게 준비물이 필요합니다. 빅스비 캡슐을 사용하기 때문에 빅스비가 내장된 갤럭시 스마트폰을 소지하셔야 합니다. 왼쪽의 웹 화면은 로봇의 LCD에서 보이는 화면입니다. 이 화면을 로봇 얼굴이라고 하겠습니다. 캡슐을 실행시키고 로봇의 카메라를 보며 인사를 하면 

인증 화면으로 넘어갑니다. 로봇 얼굴에 표시되는 인증번호를 빅스비에서 입력 후 로봇을 이용할 수 있습니다. 이는 로봇이 여러 대 있을 경우를 가정했을 때 로봇과의 커넥션을 위함입니다.

인증이 완료되면 로봇얼굴에서 현재 층의 약도를 표시하며 유저는 이동할 장소를 선택합니다.

이동을 시작하면 이동 중인 화면으로 변경되고 유저는 로봇을 따라 이동합니다. 도착 시에는 도착 버튼을 누릅니다. 만약 도착하지 않았는데 도착 버튼을 누른다면 ..... 로봇에게 잔소리를 들을 수 있습니다.!

목적지에 도착하면 안내가 종료되며, 로봇얼굴에서 장소 또는 행사에 대한 설명을 제공합니다.

만약 안내받을 장소가 다른 층이라면 이동할 수 있게 안내해줍니다. 여기까지 안내 서비스 이용 방법을 설명 드렸으며, 



확장 기능으로는 투어 기능을 제공할 수 있습니다. 예를 들면 싸피의 잡페어, 입학식 등의 행사가 있을 때 사용 가능합니다. 미리 지정된 루트로 투어를 진행하거나, 가고 싶은 특정 장소를 지정한 후 순서대로 구경할 수도 있습니다.

멀티캠퍼스 외에도 코엑스 등의 큰 행사장이나, 학교, 등 안내가 필요한 곳에서 같은 로직으로 사용할 수 있습니다. 또한, 요즘 같은 시국에 비대면으로 건물에 대한 안내를 받을 수 있어 코로나의 위험에서 벗어날 수 있다는 장점이 있습니다.



저희 로봇에 기술 스택을 말씀드리겠습니다. ROS라는 로봇 미들웨어를 사용하여 자율주행하고, 성능 및 시각화를 위해 아래와 같은 툴들을 사용합니다. 그리고 로봇 얼굴에서 보여지는 인터페이스는 리액트를 사용하고, 유저 경험은 빅스비로 이루어집니다. 백엔드에서 노드js 서버가 데이터 가공 및 중개 역할을 합니다.



이제 현재까지의 진행 상황을 말씀드리겠습니다. 부릉이를 불러보겠습니다. 현재는 영상은 시뮬레이터이지만 트레이닝 과정을 거친 후에는 직접 말로 명령할 수 있습니다.

다음으로 로봇 자율주행 SLAM 기능 테스트 영상입니다. 라이다에서 센서값을 받아와서 실내 지도를 그릴 수 있는 전초 테스트를 진행했습니다. 

로봇 모델링입니다. 왼쪽 영상과 같이 모델링을 완료하였고 장비 수령을 마쳐 로봇 프레임 조립 과정에 있습니다. 오른쪽 사진과 같이 옷 안에서 보드를 숨기고 있습니다.

마지막으로 향후 계획은 다음과 같습니다. Robot의 자율주행과 부가 기능을 완성하고, Bixby 캡슐을 개발하고, 사용자 인터페이스를 구현하고, 서버를 중심으로 모든 부분 통신을 진행함으로써 프로젝트를 완료할 예정입니다.

이상입니다.

---



모델링: 빅스비 내에서 사용할 데이터들을 정의하고, 구조를 설계하는 것

비즈니스 로직: 빅스비 내에서 자바스크립트를 통해 실제 수행되는 기능을 작성하는 것
발화 트레이닝: 음성 인식을 위해 사용자 발화의 형태들과 내용들을 분석하는 것
뷰: 비즈니스 로직 이후 도출된 최종 결과를 사용자에게 보여주는 UI/UX



할드라이버: 레지스터 건드리는 걸 도와주는 중간 라이브러리 생산성 위해 이걸 쓰기위해서 ARM CMSIS 사용

melodic: 2018년도 lts버전 ros 로봇을 동작시키는 미들웨어

gazebo: 로봇 가상 시뮬레이션 툴 물리엔진이 포함됨-실제 중력가속도, 저항 , 시그널 잡음 등 포함

rviz: 로봇 시각화 툴 시각화 그래프, 3d모델링, 우리 모델링한거랑 slam



자율주행 알고리즘: 